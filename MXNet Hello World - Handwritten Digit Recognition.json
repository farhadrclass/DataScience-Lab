{"paragraphs":[{"text":"%md\n2.3.1. Installing from a Tar File\n\n    Navigate to your <cudnnpath> directory containing the cuDNN Tar file.\n    Unzip the cuDNN package.\n\n    $ tar -xzvf cudnn-9.0-linux-x64-v7.tgz\n\n    Copy the following files into the CUDA Toolkit directory.\n\n    $ sudo cp cuda/include/cudnn.h /usr/local/cuda/include\n    $ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\n    $ sudo chmod a+r /usr/local/cuda/include/cudnn.h\n    /usr/local/cuda/lib64/libcudnn*\n\n\nRead more at: http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#ixzz55z3kRfY9\nFollow us: @GPUComputing on Twitter | NVIDIA on Facebook\n\n","user":"admin","dateUpdated":"2018-02-12T10:23:44-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517602502285_1880738394","id":"20180202-151502_265746263","dateCreated":"2018-02-02T15:15:02-0500","dateStarted":"2018-02-12T10:23:44-0500","dateFinished":"2018-02-12T10:23:44-0500","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1228","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>2.3.1. Installing from a Tar File</p>\n<pre><code>Navigate to your &lt;cudnnpath&gt; directory containing the cuDNN Tar file.\nUnzip the cuDNN package.\n\n$ tar -xzvf cudnn-9.0-linux-x64-v7.tgz\n\nCopy the following files into the CUDA Toolkit directory.\n\n$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include\n$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\n$ sudo chmod a+r /usr/local/cuda/include/cudnn.h\n/usr/local/cuda/lib64/libcudnn*\n</code></pre>\n<p>Read more at: <a href=\"http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#ixzz55z3kRfY9\">http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#ixzz55z3kRfY9</a><br/>Follow us: @GPUComputing on Twitter | NVIDIA on Facebook</p>\n</div>"}]}},{"text":"%md\n\nValidate MXNet Installation\nhttps://mxnet.incubator.apache.org/install/index.html\n\nStart the python terminal.\n\n$ python\n\nRun a short MXNet python program to create a 2X3 matrix of ones a on a GPU, multiply each element in the matrix by 2 followed by adding 1. We expect the output to be a 2X3 matrix with all elements being 3. We use mx.gpu(), to set MXNet context to be GPUs.\n","user":"admin","dateUpdated":"2018-02-12T10:23:15-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517602538000_971454150","id":"20180202-151538_874859166","dateCreated":"2018-02-02T15:15:38-0500","dateStarted":"2018-02-12T10:23:15-0500","dateFinished":"2018-02-12T10:23:17-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1229","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Validate MXNet Installation<br/><a href=\"https://mxnet.incubator.apache.org/install/index.html\">https://mxnet.incubator.apache.org/install/index.html</a></p>\n<p>Start the python terminal.</p>\n<p>$ python</p>\n<p>Run a short MXNet python program to create a 2X3 matrix of ones a on a GPU, multiply each element in the matrix by 2 followed by adding 1. We expect the output to be a 2X3 matrix with all elements being 3. We use mx.gpu(), to set MXNet context to be GPUs.</p>\n</div>"}]}},{"text":"%spark.pyspark\n\nimport mxnet as mx\na = mx.nd.ones((2, 3), mx.cpu())\nb = a * 2 + 1\nb.asnumpy()\n","user":"admin","dateUpdated":"2018-02-12T10:23:18-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517602596174_250126583","id":"20180202-151636_1141277565","dateCreated":"2018-02-02T15:16:36-0500","dateStarted":"2018-02-12T10:23:18-0500","dateFinished":"2018-02-12T10:25:48-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1230","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"array([[ 3.,  3.,  3.],\n       [ 3.,  3.,  3.]], dtype=float32)\n"}]}},{"text":"%spark.pyspark\n\n# The following source code downloads and loads the images and the corresponding labels into memory\nimport mxnet as mx\nmnist = mx.test_utils.get_mnist()","user":"admin","dateUpdated":"2018-02-09T16:13:38-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002312_763580290","id":"20180201-155702_231126127","dateCreated":"2018-02-01T16:03:22-0500","dateStarted":"2018-02-09T16:13:38-0500","dateFinished":"2018-02-09T16:13:39-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1231"},{"text":"%spark.pyspark\n\n# The following source code initializes the data iterators for the MNIST dataset. \n# Note that we initialize two iterators: one for train data and one for test data\nbatch_size = 100\ntrain_iter = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)\nval_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n","user":"admin","dateUpdated":"2018-02-09T16:13:43-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002315_763965039","id":"20180201-155742_712380526","dateCreated":"2018-02-01T16:03:22-0500","dateStarted":"2018-02-09T16:13:43-0500","dateFinished":"2018-02-09T16:13:48-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1232"},{"text":"%spark.pyspark\n\n# The first approach makes use of a Multilayer Perceptron to solve this problem\ndata = mx.sym.var('data')\n# Flatten the data from 4-D shape into 2-D (batch_size, num_channel*width*height)\ndata = mx.sym.flatten(data=data)","user":"admin","dateUpdated":"2018-02-09T16:13:54-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false},"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518196417072_-1872353693","id":"20180209-121337_768431036","dateCreated":"2018-02-09T12:13:37-0500","dateStarted":"2018-02-09T16:13:55-0500","dateFinished":"2018-02-09T16:13:55-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1233"},{"text":"%spark.pyspark\n\n# The following code declares two fully connected layers with 128 and 64 neurons each\n# The first fully-connected layer and the corresponding activation function\nfc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\nact1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n\n# The second fully-connected layer and the corresponding activation function\nfc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)\nact2 = mx.sym.Activation(data=fc2, act_type=\"relu\")","user":"admin","dateUpdated":"2018-02-09T16:13:58-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false},"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518196437260_1177012847","id":"20180209-121357_1367596215","dateCreated":"2018-02-09T12:13:57-0500","dateStarted":"2018-02-09T16:13:59-0500","dateFinished":"2018-02-09T16:13:59-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1234"},{"text":"%spark.pyspark\n\n# The following source code declares the final fully connected layer of size 10\n# MNIST has 10 classes\nfc3  = mx.sym.FullyConnected(data=act2, num_hidden=10)\n# Softmax with cross entropy loss\nmlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')","user":"admin","dateUpdated":"2018-02-09T16:14:04-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false},"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518196451577_-1698585108","id":"20180209-121411_1813095212","dateCreated":"2018-02-09T12:14:11-0500","dateStarted":"2018-02-09T16:14:04-0500","dateFinished":"2018-02-09T16:14:04-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1235"},{"text":"%spark.pyspark\n\nimport logging\nlogging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n# create a trainable module on CPU\nmlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())\n#mlp_model = mx.mod.Module(symbol=mlp, context=mx.gpu())\nmlp_model.fit(train_iter,  # train data\n              eval_data=val_iter,  # validation data\n              optimizer='sgd',  # use SGD to train\n              optimizer_params={'learning_rate':0.1},  # use fixed learning rate\n              eval_metric='acc',  # report accuracy during training\n              batch_end_callback = mx.callback.Speedometer(batch_size, 100), # output progress for each 100 data batches\n              num_epoch=10)  # train for at most 10 dataset passes","user":"admin","dateUpdated":"2018-02-09T16:14:14-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002339_754731065","id":"20180201-155834_1157246348","dateCreated":"2018-02-01T16:03:22-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1236"},{"text":"%spark.pyspark\n\n# we can evaluate the trained model by running predictions on test data\ntest_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\nprob = mlp_model.predict(test_iter)\nassert prob.shape == (10000, 10)","dateUpdated":"2018-02-01T16:04:01-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002341_752422572","id":"20180201-155846_1605032449","dateCreated":"2018-02-01T16:03:22-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1237"},{"text":"%spark.pyspark\n","user":"admin","dateUpdated":"2018-02-09T11:59:17-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518195557507_-670624703","id":"20180209-115917_412507185","dateCreated":"2018-02-09T11:59:17-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1238"},{"text":"%spark.pyspark\n\n# Convolutional Neural Network\ndata = mx.sym.var('data')\n# first conv layer\nconv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\ntanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\npool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n# second conv layer\nconv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\ntanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\npool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n# first fullc layer\nflatten = mx.sym.flatten(data=pool2)\nfc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\ntanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n# second fullc\nfc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n# softmax loss\nlenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')","dateUpdated":"2018-02-01T16:03:59-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002344_751268325","id":"20180201-155900_1258055385","dateCreated":"2018-02-01T16:03:22-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1239"},{"text":"%spark.pyspark\n\n# create a trainable module on GPU 0\nlenet_model = mx.mod.Module(symbol=lenet, context=mx.cpu())\n#lenet_model = mx.mod.Module(symbol=lenet, context=mx.gpu())\n# train with the same\nlenet_model.fit(train_iter,\n                eval_data=val_iter,\n                optimizer='sgd',\n                optimizer_params={'learning_rate':0.1},\n                eval_metric='acc',\n                batch_end_callback = mx.callback.Speedometer(batch_size, 100),\n                num_epoch=10)","dateUpdated":"2018-02-09T11:59:46-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002347_751653074","id":"20180201-155913_1504384219","dateCreated":"2018-02-01T16:03:22-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1240"},{"text":"%spark.pyspark\n\n#  use the trained LeNet model to generate predictions for the test data\ntest_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\nprob = lenet_model.predict(test_iter)\ntest_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n# predict accuracy for lenet\nacc = mx.metric.Accuracy()\nlenet_model.score(test_iter, acc)\nprint(acc)\nassert acc.get()[1] > 0.98","dateUpdated":"2018-02-01T16:03:55-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002350_750498827","id":"20180201-155926_990067595","dateCreated":"2018-02-01T16:03:22-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1241"},{"text":"%spark.pyspark\n","dateUpdated":"2018-02-01T16:03:52-0500","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517519002352_760502299","id":"20180201-155952_1819939762","dateCreated":"2018-02-01T16:03:22-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1242"}],"name":"MXNet Hello World - Handwritten Digit Recognition","id":"2D5UGA3D7","angularObjects":{"2CKX8WPU1:shared_process":[],"2CKAY1A8Y:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}