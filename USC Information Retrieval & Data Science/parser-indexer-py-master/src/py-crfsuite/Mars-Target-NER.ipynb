{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Target Encyclopedia  - NER\n",
    "Thamme Gowda (Thamme.Gowda@jpl.nasa.gov)\n",
    "\n",
    "Named Entity Recognition / Sequence Tagging\n",
    "This notebook contains NER tagging using CRF suite\n",
    "\n",
    "\n",
    "### Notes:\n",
    " + Use python3, Reason: we need unicode strings, which is default in python3\n",
    " + install Python-crfsuite\n",
    " + Start CoreNLP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from codecs import open as copen\n",
    "from collections import defaultdict as ddict\n",
    "from csv import DictWriter\n",
    "import sys\n",
    "from copy import copy\n",
    "import time\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import os, glob\n",
    "import pickle\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#accept_labels = set(['Element', 'Mineral', 'Target', 'Material', 'Locality', 'Site'])\n",
    "accept_labels = set(['Target', 'Mineral', 'Element'])\n",
    "\n",
    "class BratToCRFSuitFeaturizer(object):\n",
    "    def __init__(self, corenlp_url='http://localhost:9000', iob=False):\n",
    "        '''\n",
    "        Create Converter for converting brat annotations to Core NLP NER CRF\n",
    "        classifier training data.\n",
    "        @param corenlp_url: URL to corenlp server.\n",
    "                To start the server checkout: http://stanfordnlp.github.io/CoreNLP/corenlp-server.html#getting-started\n",
    "        @param iob: set 'True' for IOB encoding\n",
    "        '''\n",
    "        self.corenlp = StanfordCoreNLP(corenlp_url)\n",
    "        self.iob = iob\n",
    "\n",
    "    def convert(self, text_file, ann_file):\n",
    "        text, tree = self.parse(text_file, ann_file)\n",
    "        props = { 'annotators': 'tokenize,ssplit,lemma,pos,ner', 'outputFormat': 'json'}\n",
    "        if text[0].isspace():\n",
    "            text = '.' + text[1:]\n",
    "            # Reason: some tools trim/strip off the white spaces\n",
    "            # which will mismatch the character offsets\n",
    "        output = self.corenlp.annotate(text, properties=props)\n",
    "        records = []\n",
    "        for sentence in output['sentences']:\n",
    "            sent_features = []\n",
    "            continue_ann, continue_ann_en = None, None\n",
    "            for tok in sentence['tokens']:\n",
    "                begin, tok_end = tok['characterOffsetBegin'], tok['characterOffsetEnd']\n",
    "                label = 'O'\n",
    "                if begin in tree:\n",
    "                    node = tree[begin]\n",
    "                    if len(node) > 1:\n",
    "                        print(\"WARN: multiple starts at \", begin, node)\n",
    "                        if tok_end in node:\n",
    "                            node = {tok_end: node[tok_end]} # picking one\n",
    "                            print(\"Chose:\", node)\n",
    "\n",
    "                    ann_end, labels = list(node.items())[0]\n",
    "                    if not len(labels) == 1:\n",
    "                        print(\"WARN: Duplicate labels for token: %s, label:%s.\\\n",
    "                              Using the first one!\" % (tok['word'], str(labels)))\n",
    "                    if accept_labels is not None and labels[0] in accept_labels:\n",
    "                        label = labels[0]\n",
    "\n",
    "                    if tok_end == ann_end: # annotation ends where token ends\n",
    "                        continue_ann = None\n",
    "                    elif tok_end < ann_end and label != 'O':\n",
    "                        #print(\"Continue for the next %d chars\" % (ann_end - tok_end))\n",
    "                        continue_ann = label\n",
    "                        continue_ann_end = ann_end \n",
    "                    if label != 'O' and self.iob:\n",
    "                        label = \"B-\" + label\n",
    "                elif continue_ann is not None and tok_end <= continue_ann_end:\n",
    "                    #print(\"Continuing the annotation %s, %d:%d %d]\" % \n",
    "                    #(continue_ann, begin, tok_end, continue_ann_end))\n",
    "                    label = continue_ann            # previous label is this label\n",
    "                    if continue_ann_end == tok_end: # continuation ends here\n",
    "                        #print(\"End\")\n",
    "                        continue_ann = None\n",
    "                    if self.iob:\n",
    "                        label = \"I-\" + label\n",
    "                sent_features.append([tok['word'], tok['lemma'], tok['pos'], tok['ner'], label])\n",
    "            yield sent_features\n",
    "\n",
    "    def parse(self, txt_file, ann_file):\n",
    "        with copen(ann_file, 'r', encoding='utf-8') as ann_file:\n",
    "            with copen(txt_file, 'r', encoding='utf-8') as text_file:\n",
    "                texts = text_file.read()\n",
    "            anns = map(lambda x: x.strip().split('\\t'), ann_file)\n",
    "            anns = filter(lambda x: len(x) > 2, anns)\n",
    "            # FIXME: ignoring the annotatiosn which are complex\n",
    "\n",
    "            anns = filter(lambda x: ';' not in x[1], anns)\n",
    "            # FIXME: some annotations' spread have been split into many, separated by ; ignoring them\n",
    "\n",
    "            def __parse_ann(ann):\n",
    "                spec = ann[1].split()\n",
    "                name = spec[0]\n",
    "                markers = list(map(lambda x: int(x), spec[1:]))\n",
    "                #t = ' '.join([texts[begin:end] for begin,end in zip(markers[::2], markers[1::2])])\n",
    "                t = texts[markers[0]:markers[1]]\n",
    "                if not t == ann[2]:\n",
    "                    print(\"Error: Annotation mis-match, file=%s, ann=%s\" % (txt_file, str(ann)))\n",
    "                    return None\n",
    "                return (name, markers, t)\n",
    "            anns = map(__parse_ann, anns) # format\n",
    "            anns = filter(lambda x: x, anns) # skip None\n",
    "\n",
    "            # building a tree index for easy accessing\n",
    "            tree = {}\n",
    "            for entity_type, pos, name in anns:\n",
    "                if entity_type not in accept_labels:\n",
    "                    continue\n",
    "                begin, end = pos[0], pos[1]\n",
    "                if begin not in tree:\n",
    "                    tree[begin] = {}\n",
    "                node = tree[begin]\n",
    "                if end not in node:\n",
    "                    node[end] = []\n",
    "                node[end].append(entity_type)\n",
    "\n",
    "            # Re-read file in without decoding it\n",
    "            text_file = copen(txt_file, 'r', encoding='utf-8')\n",
    "            texts = text_file.read()\n",
    "            text_file.close()\n",
    "            return texts, tree\n",
    "\n",
    "def scan_dir(dir_name):\n",
    "    items = glob.glob(dir_name + \"/*.ann\")\n",
    "    items = map(lambda f: (f, f.replace(\".ann\", \".txt\")), items)\n",
    "    return items\n",
    "\n",
    "def preprocess_all(list_file, out_file):\n",
    "    featzr = BratToCRFSuitFeaturizer(iob=True)\n",
    "    tokenized = []\n",
    "    with open(list_file) as f:\n",
    "        examples = map(lambda l:l.strip().split(','), f.readlines())\n",
    "    for txt_file, ann_file in examples:\n",
    "        sents = featzr.convert(txt_file, ann_file)\n",
    "        tokenized.append(list(sents))\n",
    "\n",
    "    pickle.dump(tokenized, open(out_file, 'wb'))\n",
    "    print(\"Dumped %d docs to %s\" % (len(tokenized), out_file))\n",
    "\n",
    "#######################\n",
    "# Evaluates the model\n",
    "def evaluate(tagger, corpus_file):\n",
    "    \n",
    "    corpus = pickle.load(open(corpus_file, 'rb'))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for doc in corpus:\n",
    "        seq = merge_sequences(doc)\n",
    "        truth = seq2labels(seq)\n",
    "        preds = tagger.tag(seq2features(seq))\n",
    "        assert len(truth) == len(preds)\n",
    "        y_true.extend(truth)\n",
    "        y_pred.extend(preds)    \n",
    "    assert len(y_true) == len(y_pred)\n",
    "    table = ddict(lambda: ddict(int)) \n",
    "    for truth, pred in zip(y_true, y_pred):\n",
    "        table[truth][pred] += 1\n",
    "        table[truth]['total'] += 1\n",
    "        table['total'][pred] += 1\n",
    "        table['total']['total'] += 1\n",
    "    keys = []\n",
    "    for label in accept_labels:\n",
    "        keys.append('B-%s' % label)\n",
    "        keys.append('I-%s' % label)\n",
    "    col_keys = copy(keys)\n",
    "    precision, recall = {}, {}\n",
    "    for k in set(keys):\n",
    "        tot_preds = table['total'][k]\n",
    "        tot_truth = table[k]['total']\n",
    "        table['Precision'][k] = \"%.4f\" % (float(table[k][k]) / tot_preds) if tot_preds else 0 \n",
    "        table['Recall'][k] = \"%.4f\" % (float(table[k][k]) / tot_truth) if tot_truth else 0 \n",
    "    col_keys.extend(['O', 'total'])\n",
    "    keys.extend(['', 'Precision', 'Recall', '', 'O', 'total'])\n",
    "    return table, keys, col_keys\n",
    "\n",
    "\n",
    "def printtable(table, row_keys, col_keys, delim=','):\n",
    "    \"\"\"\n",
    "    print table in CSV format which is meant to be copy pasted to Excel sheet \n",
    "    \"\"\"\n",
    "    f = sys.stdout\n",
    "    out = DictWriter(f, delimiter=delim, restval=0, fieldnames=col_keys)\n",
    "    f.write(\"%s%s\" % (\"***\", delim))\n",
    "    out.writeheader()\n",
    "    for k in row_keys:\n",
    "        if not k.strip():\n",
    "            f.write(\"\\n\")\n",
    "            continue\n",
    "        f.write(\"%s%s\" % (k, delim))\n",
    "        out.writerow(table[k])\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and store the corpus\n",
    "\n",
    "In this step, we pass the text through CoreNLP pipeline, tokenize and POS tag them. \n",
    "In addition, we lookup the annotations file and match the target annotations with the token. \n",
    "\n",
    "Since this step is expensive, we store the results in pickle file, so that we can later load and resume our analysis for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_dir = \"/Users/thammegr/work/mte/data/newcorpus/workspace\"\n",
    "train_list = p_dir + \"/train_62r15_685k14_384k15.list\"\n",
    "dev_list= p_dir + \"/development.list\"\n",
    "test_list = p_dir + \"/test.list\"\n",
    "\n",
    "train_corpus_file = 'mte-corpus-train.pickle'\n",
    "preprocess_all(train_list, train_corpus_file)\n",
    "\n",
    "# Test and Development set\n",
    "dev_corpus_file = 'mte-corpus-dev.pickle'\n",
    "preprocess_all(dev_list, dev_corpus_file)\n",
    "test_corpus_file = 'mte-corpus-test.pickle'\n",
    "preprocess_all(test_list, test_corpus_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the corpus\n",
    "Here we load the corpus from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hollow', 'hollow', 'JJ', 'O', 'O'],\n",
       " ['spherical', 'spherical', 'JJ', 'O', 'O'],\n",
       " ['feature', 'feature', 'NN', 'O', 'O'],\n",
       " ['observed', 'observe', 'VBN', 'O', 'O'],\n",
       " ['on', 'on', 'IN', 'O', 'O'],\n",
       " ['sol', 'sol', 'NN', 'O', 'O'],\n",
       " ['122', '122', 'CD', 'NUMBER', 'O'],\n",
       " ['in', 'in', 'IN', 'O', 'O'],\n",
       " ['the', 'the', 'DT', 'O', 'O'],\n",
       " ['Yellowknife', 'Yellowknife', 'NNP', 'LOCATION', 'O'],\n",
       " ['Bay', 'Bay', 'NNP', 'LOCATION', 'O'],\n",
       " ['area', 'area', 'NN', 'O', 'O'],\n",
       " ['.', '.', '.', 'O', 'O']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file = 'mte-corpus-train.pickle'\n",
    "corpus = pickle.load(open(corpus_file, 'rb'))\n",
    "corpus[0][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start playing with the features of CRF Suite to build a sequence tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features:\n",
      "['hollow', 'hollow', 'JJ', 'O', 'O']\n",
      "['.', '.', '.', 'O', 'O']\n",
      "['|', '|', '|', 'O', 'O']\n",
      "['No', 'no', 'DT', 'O', 'O']\n",
      "['such', 'such', 'JJ', 'O', 'O']\n",
      "['features', 'feature', 'NNS', 'O', 'O']\n",
      "['were', 'be', 'VBD', 'O', 'O']\n",
      "['observed', 'observe', 'VBN', 'O', 'O']\n",
      "['across', 'across', 'IN', 'O', 'O']\n",
      "['Bradbury', 'Bradbury', 'NNP', 'O', 'O']\n",
      "['Rise', 'rise', 'NN', 'O', 'O']\n",
      "[',', ',', ',', 'O', 'O']\n",
      "-1word.bias\n",
      "-1word.genpos=NN\n",
      "-1word[-1:]=s\n",
      "-1word[-2:]=es\n",
      "-1word[-3:]=res\n",
      "-1word.islower=True\n",
      "-1word.isupper=False\n",
      "-1word.istitle=False\n",
      "-1word.shape=cvvcvcvc\n",
      "-1word.text=features\n",
      "0word.bias\n",
      "0word.genpos=VB\n",
      "0word[-1:]=e\n",
      "0word[-2:]=re\n",
      "0word[-3:]=ere\n",
      "0word.islower=True\n",
      "0word.isupper=False\n",
      "0word.istitle=False\n",
      "0word.shape=cvcv\n",
      "0word.text=were\n",
      "1word.bias\n",
      "1word.genpos=VB\n",
      "1word[-1:]=d\n",
      "1word[-2:]=ed\n",
      "1word[-3:]=ved\n",
      "1word.islower=True\n",
      "1word.isupper=False\n",
      "1word.istitle=False\n",
      "1word.shape=vccvccvc\n",
      "1word.text=observed\n",
      "['feature.minfreq',\n",
      " 'feature.possible_states',\n",
      " 'feature.possible_transitions',\n",
      " 'c1',\n",
      " 'c2',\n",
      " 'max_iterations',\n",
      " 'num_memories',\n",
      " 'epsilon',\n",
      " 'period',\n",
      " 'delta',\n",
      " 'linesearch',\n",
      " 'max_linesearch']\n",
      "{'NER': False,\n",
      " 'POS': False,\n",
      " 'bias': True,\n",
      " 'context': [-1, 0, 1],\n",
      " 'gen_POS': True,\n",
      " 'is_lower': True,\n",
      " 'is_title': True,\n",
      " 'is_upper': True,\n",
      " 'max_suffix_chars': 3,\n",
      " 'text': True,\n",
      " 'wordshape': 'sound'}\n",
      "Training Time: 133.967s\n",
      "\n",
      "Evaluating on Development Set\n",
      "\n",
      "***,B-Mineral,I-Mineral,B-Target,I-Target,B-Element,I-Element,O,total\n",
      "B-Mineral,195,0,0,0,1,0,44,240\n",
      "I-Mineral,0,0,0,0,0,0,0,0\n",
      "B-Target,0,0,36,0,0,0,111,147\n",
      "I-Target,0,0,0,8,0,0,6,14\n",
      "B-Element,0,0,0,0,331,0,44,375\n",
      "I-Element,0,0,0,0,0,0,0,0\n",
      "\n",
      "Precision,0.9701,0,0.9730,0.8889,0.8874,0,0,0\n",
      "Recall,0.8125,0,0.2449,0.5714,0.8827,0,0,0\n",
      "\n",
      "O,6,0,1,1,41,0,34145,34194\n",
      "total,201,0,37,9,373,0,34350,34970\n",
      "\n",
      "\n",
      "Evaluating on Test Set\n",
      "\n",
      "***,B-Mineral,I-Mineral,B-Target,I-Target,B-Element,I-Element,O,total\n",
      "B-Mineral,265,0,0,0,0,0,47,312\n",
      "I-Mineral,1,0,0,0,0,0,2,3\n",
      "B-Target,0,0,57,0,0,0,137,194\n",
      "I-Target,0,0,0,8,0,0,12,20\n",
      "B-Element,0,0,0,0,431,0,27,458\n",
      "I-Element,0,0,0,0,0,0,0,0\n",
      "\n",
      "Precision,0.9707,0,0.9048,0.8889,0.8725,0,0,0\n",
      "Recall,0.8494,0.0000,0.2938,0.4000,0.9410,0,0,0\n",
      "\n",
      "O,7,0,6,1,63,0,59566,59643\n",
      "total,273,0,63,9,494,0,59791,60630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "config = {\n",
    "    'POS': False,\n",
    "    'gen_POS': True, # generalize POS\n",
    "    'bias': True,\n",
    "    'max_suffix_chars': 3,\n",
    "    'is_lower': True,\n",
    "    'is_upper': True,\n",
    "    'is_title': True,\n",
    "    'text': True,\n",
    "    'wordshape': 'sound',\n",
    "    'NER': False, # default NER\n",
    "    'context': list(range(-1, 2))\n",
    "}\n",
    "\n",
    "def get_wordshape_general(word):\n",
    "    \"\"\"\n",
    "    Makes shape of the word based on upper case, lowercase or digit\n",
    "    \"\"\"\n",
    "    # Note : the order of replacement matters, digits should be at the last\n",
    "    return re.sub(\"[0-9]\", 'd', \n",
    "                  re.sub(\"[A-Z]\", 'X',\n",
    "                         re.sub(\"[a-z]\", 'x', word)))\n",
    "\n",
    "def get_wordshape_sound(word):\n",
    "    \"\"\"\n",
    "    Makes shape of word based on the vowel or consonenet sound\n",
    "    \"\"\"\n",
    "    # Note : the order of replacement matters, c, v, d in order\n",
    "    word = re.sub(\"[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]\", 'c', word) # consonents\n",
    "    word = re.sub(\"[AEIOUaeiou]\", 'v', word) # vowels\n",
    "    word = re.sub(\"[0-9]\", 'd', word) # digits\n",
    "    return word\n",
    "\n",
    "def get_wordshape_sound_case(word):\n",
    "    \"\"\"\n",
    "    Makes shape of word based on the vowel or consonenet sound considering case\n",
    "    \"\"\"\n",
    "    word = re.sub(\"[bcdfghjklmnpqrstvwxyz]\", 'c', word) # consonents\n",
    "    word = re.sub(\"[BCDFGHJKLMNPQRSTVWXYZ]\", 'C', word) # upper consonents\n",
    "    word = re.sub(\"[aeiou]\", 'v', word) # vowels\n",
    "    word = re.sub(\"[AEIOU]\", 'V', word) # upper vowels\n",
    "    word = re.sub(\"[+-]?[0-9]+(\\.[0-9]+)?\", 'N', word) # digits\n",
    "    return word\n",
    "\n",
    "def word2features(sent, idx):\n",
    "    word = sent[idx]\n",
    "    words = []\n",
    "    feats = []\n",
    "\n",
    "    # Context\n",
    "    context = set(config.get('context', []))\n",
    "    context.add(0)  # current word\n",
    "    for ctx in sorted(context):\n",
    "        pos = ctx + idx\n",
    "        if pos >= 0 and pos < len(sent):\n",
    "            words.append((str(ctx), sent[pos]))\n",
    "    \n",
    "    if idx == 0:\n",
    "        feats.append('BOS') # begin of sequence\n",
    "    if idx == len(sent) - 1:\n",
    "        feats.append('EOS')\n",
    "    for prefix, word in words:\n",
    "        assert len(word) == 5\n",
    "        txt, lemma, POS, ner, label = word \n",
    "        if config.get('bias'):\n",
    "            feats.append('%sword.bias'% (prefix))\n",
    "        if config.get('POS'):\n",
    "            feats.append('%sword.pos=%s' %(prefix, POS))\n",
    "        if config.get('gen_POS'):\n",
    "            feats.append('%sword.genpos=%s' %(prefix, POS[:2]))\n",
    "        if config.get('max_suffix_chars'):\n",
    "            for i in range(1, config.get('max_suffix_chars', -1) + 1):\n",
    "                if len(txt) < i:\n",
    "                    break\n",
    "                feats.append('%sword[-%d:]=%s' % (prefix, i, txt[-i:]))\n",
    "        if config.get('is_lower'):\n",
    "            feats.append('%sword.islower=%s' % (prefix, txt.islower()))\n",
    "        if config.get('is_upper'):\n",
    "            feats.append('%sword.isupper=%s' % (prefix, txt.isupper()))\n",
    "        if config.get('is_title'):\n",
    "            feats.append('%sword.istitle=%s' % (prefix, txt.istitle()))\n",
    "        if config.get('wordshape'):\n",
    "            shape = config['wordshape'] \n",
    "            if shape == 'general':\n",
    "                shape_val = get_wordshape_general(txt)\n",
    "            elif shape == 'sound':\n",
    "                shape_val = get_wordshape_sound(txt)\n",
    "            elif shape == 'sound_case':\n",
    "                shape_val = get_wordshape_sound_case(txt)\n",
    "            else:\n",
    "                raise Error(\"Word Shape spec unknown '%s'\" % config['wordshape'])\n",
    "            feats.append('%sword.shape=%s' % (prefix, shape_val))\n",
    "        if config.get('NER'):\n",
    "            feats.append('%sword.ner=%s' % (prefix, ner))\n",
    "        if config.get('text'):\n",
    "            feats.append('%sword.text=%s' % (prefix, txt))\n",
    "    return feats\n",
    "\n",
    "def seq2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def seq2labels(sent):\n",
    "    # Assumption the last one in array is always a label\n",
    "    return [tok[-1] for tok in sent] \n",
    "\n",
    "def merge_sequences(doc):\n",
    "    '''\n",
    "    document contains multiple sentences. here all sentences in document are merged to form one large sequence.\n",
    "    '''\n",
    "    res = []\n",
    "    for seq in doc:\n",
    "        res.extend(seq)\n",
    "        res.append(['|', '|', '|', 'O', 'O']) # sentence end marker\n",
    "    return res\n",
    "  \n",
    "\n",
    "def train(corpus, model_file):\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "    # Load training examples\n",
    "    flag = True\n",
    "    for doc in corpus:\n",
    "        seq = merge_sequences(doc)\n",
    "        x_seq = seq2features(seq)\n",
    "        if flag:\n",
    "            p = 403\n",
    "            print(\"Sample features:\")\n",
    "            print(\"\\n\".join(map(str, seq[p-6:p+6])))\n",
    "            print(\"\\n\".join(x_seq[p]))\n",
    "            flag = False\n",
    "        y_seq = seq2labels(seq)\n",
    "        trainer.append(x_seq, y_seq)\n",
    "\n",
    "    trainer.set_params({\n",
    "        'c1': 0.5,   # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 50,  # stop earlier\n",
    "        # include transitions that are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "    })\n",
    "\n",
    "\n",
    "    st = time.time()\n",
    "    pprint(trainer.params())\n",
    "    pprint(config)\n",
    "    trainer.train(model_file)\n",
    "    print(\"Training Time: %.3fs\" % (time.time() - st))\n",
    "\n",
    "model_file = 'jpl-mars-target-ner-model.crfsuite'\n",
    "train(corpus, model_file)\n",
    "\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model_file)\n",
    "print(\"\\nEvaluating on Development Set\\n\")\n",
    "dev_corpus_file = 'mte-corpus-dev.pickle'\n",
    "printtable(*evaluate(tagger, dev_corpus_file))\n",
    "\n",
    "print(\"\\nEvaluating on Test Set\\n\")\n",
    "test_corpus_file = 'mte-corpus-test.pickle'\n",
    "printtable(*evaluate(tagger, test_corpus_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx, Truth, Predicted, Word, Comment \n",
      " 500         O         O       -3 ['Cooperstown', 'Cooperstown', 'NNP', 'LOCATION', 'O']\n",
      " 501         O         O       -2 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 502         O         O       -1 ['-4.62', '-4.62', 'CD', 'NUMBER', 'O']\n",
      " 503         O B-Element    <ERR> ['N', 'n', 'NN', 'O', 'O']\n",
      " 504         O         O        1 [',', ',', ',', 'O', 'O']\n",
      " 505         O         O        2 ['137.42', '137.42', 'CD', 'NUMBER', 'O']\n",
      " 506         O         O        3 ['E', 'e', 'NN', 'O', 'O']\n",
      "\n",
      " 550         O         O       -3 ['Kimberley', 'kimberley', 'NN', 'PERSON', 'O']\n",
      " 551         O         O       -2 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 552         O         O       -1 ['-4.64', '-4.64', 'CD', 'NUMBER', 'O']\n",
      " 553         O B-Element    <ERR> ['N', 'n', 'NN', 'O', 'O']\n",
      " 554         O         O        1 [',', ',', ',', 'O', 'O']\n",
      " 555         O         O        2 ['137.4', '137.4', 'CD', 'NUMBER', 'O']\n",
      " 556         O         O        3 ['E', 'e', 'NN', 'O', 'O']\n",
      "\n",
      "1536         O         O       -3 ['.', '.', '.', 'O', 'O']\n",
      "1537         O         O       -2 ['|', '|', '|', 'O', 'O']\n",
      "1538         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1539         O B-Element    <ERR> ['B', 'b', 'NN', 'O', 'O']\n",
      "1540         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "1541         O         O        2 ['Na2O', 'na2o', 'NN', 'O', 'O']\n",
      "1542         O         O        3 ['versus', 'versus', 'CC', 'O', 'O']\n",
      "\n",
      " 412         O         O       -3 ['using', 'use', 'VBG', 'O', 'O']\n",
      " 413         O         O       -2 ['a', 'a', 'DT', 'O', 'O']\n",
      " 414         O         O       -1 ['1064-nm', '1064-nm', 'JJ', 'O', 'O']\n",
      " 415         O B-Element    <ERR> ['Nd', 'nd', 'NN', 'O', 'O']\n",
      " 416         O         O        1 [':', ':', ':', 'O', 'O']\n",
      " 417         O         O        2 ['YAG', 'yag', 'NN', 'O', 'O']\n",
      " 418         O         O        3 ['q-switched', 'q-switched', 'JJ', 'O', 'O']\n",
      "\n",
      " 951         O         O       -3 ['The', 'the', 'DT', 'O', 'O']\n",
      " 952         O         O       -2 ['ratio', 'ratio', 'NN', 'O', 'O']\n",
      " 953         O         O       -1 ['of', 'of', 'IN', 'O', 'O']\n",
      " 954         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O', 'O']\n",
      " 955         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 956         O         O        2 ['II', 'II', 'NNP', 'O', 'O']\n",
      " 957         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      " 994         O         O       -3 ['|', '|', '|', 'O', 'O']\n",
      " 995         O         O       -2 ['The', 'the', 'DT', 'O', 'O']\n",
      " 996         O         O       -1 ['flat', 'flat', 'JJ', 'O', 'O']\n",
      " 997         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O', 'O']\n",
      " 998         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 999         O         O        2 ['II', 'II', 'NNP', 'O', 'O']\n",
      "1000         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1050         O         O       -3 ['.', '.', '.', 'O', 'O']\n",
      "1051         O         O       -2 ['|', '|', '|', 'O', 'O']\n",
      "1052         O         O       -1 ['Decreasing', 'decrease', 'VBG', 'O', 'O']\n",
      "1053         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O', 'O']\n",
      "1054         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1055         O         O        2 ['II', 'II', 'NNP', 'O', 'O']\n",
      "1056         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1068         O         O       -3 ['collection', 'collection', 'NN', 'O', 'O']\n",
      "1069         O         O       -2 ['suggest', 'suggest', 'VBP', 'O', 'O']\n",
      "1070         O         O       -1 ['that', 'that', 'IN', 'O', 'O']\n",
      "1071         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O', 'O']\n",
      "1072         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1073         O         O        2 ['II', 'II', 'NNP', 'O', 'O']\n",
      "1074         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1073         O         O       -3 ['II', 'II', 'NNP', 'O', 'O']\n",
      "1074         O         O       -2 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "1075         O         O       -1 ['and', 'and', 'CC', 'O', 'O']\n",
      "1076         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O', 'O']\n",
      "1077         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1078         O         O        2 ['I', 'I', 'PRP', 'O', 'O']\n",
      "1079         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1086         O         O       -3 ['plasma', 'plasma', 'NN', 'O', 'O']\n",
      "1087         O         O       -2 [',', ',', ',', 'O', 'O']\n",
      "1088         O         O       -1 ['and', 'and', 'CC', 'O', 'O']\n",
      "1089         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'MISC', 'O']\n",
      "1090         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1091         O         O        2 ['I', 'I', 'PRP', 'O', 'O']\n",
      "1092         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1111         O         O       -3 ['who', 'who', 'WP', 'O', 'O']\n",
      "1112         O         O       -2 ['found', 'find', 'VBD', 'O', 'O']\n",
      "1113         O         O       -1 ['that', 'that', 'IN', 'O', 'O']\n",
      "1114         O B-Element    <ERR> ['Al', 'Al', 'NNP', 'O', 'O']\n",
      "1115         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1116         O         O        2 ['II', 'II', 'NNP', 'O', 'O']\n",
      "1117         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1118         O         O       -3 ['propagates', 'propagate', 'VBZ', 'O', 'O']\n",
      "1119         O         O       -2 ['vertically', 'vertically', 'RB', 'O', 'O']\n",
      "1120         O         O       -1 ['while', 'while', 'IN', 'O', 'O']\n",
      "1121         O B-Element    <ERR> ['Al', 'Al', 'NNP', 'O', 'O']\n",
      "1122         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1123         O         O        2 ['I', 'I', 'PRP', 'O', 'O']\n",
      "1124         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      " 457         O         O       -3 ['telescope', 'telescope', 'NN', 'O', 'O']\n",
      " 458         O         O       -2 [',', ',', ',', 'O', 'O']\n",
      " 459         O         O       -1 ['a', 'a', 'DT', 'O', 'O']\n",
      " 460         O B-Element    <ERR> ['Nd', 'nd', 'NN', 'O', 'O']\n",
      " 461         O         O        1 [':', ':', ':', 'O', 'O']\n",
      " 462         O         O        2 ['YAG', 'yag', 'NN', 'O', 'O']\n",
      " 463         O         O        3 ['laser', 'laser', 'NN', 'O', 'O']\n",
      "\n",
      "  26         O         O       -3 ['T.', 'T.', 'NNP', 'O', 'O']\n",
      "  27         O         O       -2 ['Dequaire1', 'Dequaire1', 'NNP', 'O', 'O']\n",
      "  28         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      "  29         O B-Element    <ERR> ['P', 'p', 'NN', 'O', 'O']\n",
      "  30         O         O        1 [',', ',', ',', 'O', 'O']\n",
      "  31         O         O        2 ['Y.', 'Y.', 'NNP', 'O', 'O']\n",
      "  32         O         O        3 ['Meslin2', 'Meslin2', 'NNP', 'O', 'O']\n",
      "\n",
      "  79         O         O       -3 [',', ',', ',', 'O', 'O']\n",
      "  80         O         O       -2 ['1LISA', '1lisa', 'NN', 'O', 'O']\n",
      "  81         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      "  82         O B-Element    <ERR> ['Cr', 'cr', 'NN', 'O', 'O']\n",
      "  83         O         O        1 ['teilParis', 'teilparis', 'NN', 'O', 'O']\n",
      "  84         O         O        2 [',', ',', ',', 'O', 'O']\n",
      "  85         O         O        3 ['France', 'France', 'NNP', 'LOCATION', 'O']\n",
      "\n",
      "1699         O         O       -3 ['reveal', 'reveal', 'VBP', 'O', 'O']\n",
      "1700         O         O       -2 ['detections', 'detection', 'NNS', 'O', 'O']\n",
      "1701         O         O       -1 ['of', 'of', 'IN', 'O', 'O']\n",
      "1702         O B-Element    <ERR> ['N', 'n', 'NN', 'O', 'O']\n",
      "1703         O         O        1 [',', ',', ',', 'O', 'O']\n",
      "1704         O B-Element        2 ['H', 'h', 'NN', 'O', 'O']\n",
      "1705         O         O        3 ['and', 'and', 'CC', 'O', 'O']\n",
      "\n",
      "1701         O         O       -3 ['of', 'of', 'IN', 'O', 'O']\n",
      "1702         O B-Element       -2 ['N', 'n', 'NN', 'O', 'O']\n",
      "1703         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      "1704         O B-Element    <ERR> ['H', 'h', 'NN', 'O', 'O']\n",
      "1705         O         O        1 ['and', 'and', 'CC', 'O', 'O']\n",
      "1706         O         O        2 ['C.', 'C.', 'NNP', 'O', 'O']\n",
      "1707         O         O        3 ['1364', '1364', 'CD', 'DATE', 'O']\n",
      "\n",
      "  30         O         O       -3 ['.', '.', '.', 'O', 'O']\n",
      "  31         O         O       -2 ['|', '|', '|', 'O', 'O']\n",
      "  32         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "  33         O B-Element    <ERR> ['B', 'b', 'NN', 'O', 'O']\n",
      "  34         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "  35         O         O        2 ['MAHLI', 'mahli', 'NN', 'O', 'O']\n",
      "  36         O         O        3 ['image', 'image', 'NN', 'O', 'O']\n",
      "\n",
      " 662         O         O       -3 ['are', 'be', 'VBP', 'O', 'O']\n",
      " 663         O         O       -2 ['armored', 'armored', 'JJ', 'O', 'O']\n",
      " 664         O         O       -1 ['by', 'by', 'IN', 'O', 'O']\n",
      " 665         O B-Element    <ERR> ['medium', 'medium', 'NN', 'O', 'O']\n",
      " 666         O         O        1 ['to', 'to', 'TO', 'O', 'O']\n",
      " 667         O         O        2 ['coarse', 'coarse', 'JJ', 'O', 'O']\n",
      " 668         O         O        3 ['sand', 'sand', 'NN', 'O', 'O']\n",
      "\n",
      "1155         O         O       -3 ['absorptions', 'absorption', 'NNS', 'O', 'O']\n",
      "1156         O         O       -2 ['indicating', 'indicate', 'VBG', 'O', 'O']\n",
      "1157         O         O       -1 ['dominantly', 'dominantly', 'RB', 'O', 'O']\n",
      "1158         O B-Element    <ERR> ['Fe', 'Fe', 'NNP', 'O', 'O']\n",
      "1159         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1160         O         O        2 ['II', 'II', 'NNP', 'O', 'O']\n",
      "1161         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1161         O         O       -3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "1162         O         O       -2 ['rather', 'rather', 'RB', 'O', 'O']\n",
      "1163         O         O       -1 ['than', 'than', 'IN', 'O', 'O']\n",
      "1164         O B-Element    <ERR> ['Fe', 'Fe', 'NNP', 'O', 'O']\n",
      "1165         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1166         O         O        2 ['III', 'III', 'NNP', 'O', 'O']\n",
      "1167         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1052         O         O       -3 ['have', 'have', 'VB', 'O', 'O']\n",
      "1053         O         O       -2 ['a', 'a', 'DT', 'O', 'O']\n",
      "1054         O         O       -1 ['high', 'high', 'JJ', 'O', 'O']\n",
      "1055         O B-Element    <ERR> ['Ca', 'ca', 'NN', 'O', 'O']\n",
      "1056         O         O        1 ['+', '+', 'CC', 'O', 'O']\n",
      "1057         O         O        2 ['Na', 'na', 'NN', 'O', 'O']\n",
      "1058         O         O        3 ['+', '+', 'CC', 'O', 'O']\n",
      "\n",
      "1333 B-Mineral         O       -3 ['andesine', 'andesine', 'NN', 'O', 'B-Mineral']\n",
      "1334         O         O       -2 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1335         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1336         O B-Element    <ERR> ['Ca', 'ca', 'NN', 'O', 'O']\n",
      "1337         O         O        1 [',', ',', ',', 'O', 'O']\n",
      "1338         O B-Element        2 ['Na', 'na', 'NN', 'MISC', 'O']\n",
      "1339         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1335         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1336         O B-Element       -2 ['Ca', 'ca', 'NN', 'O', 'O']\n",
      "1337         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      "1338         O B-Element    <ERR> ['Na', 'na', 'NN', 'MISC', 'O']\n",
      "1339         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "1340         O         O        2 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1341         O B-Element        3 ['Al', 'Al', 'NNP', 'O', 'O']\n",
      "\n",
      "1338         O B-Element       -3 ['Na', 'na', 'NN', 'MISC', 'O']\n",
      "1339         O         O       -2 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "1340         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1341         O B-Element    <ERR> ['Al', 'Al', 'NNP', 'O', 'O']\n",
      "1342         O         O        1 [',', ',', ',', 'O', 'O']\n",
      "1343         O B-Element        2 ['Si', 'Si', 'NNP', 'O', 'O']\n",
      "1344         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      "1340         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      "1341         O B-Element       -2 ['Al', 'Al', 'NNP', 'O', 'O']\n",
      "1342         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      "1343         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O', 'O']\n",
      "1344         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "1345         O         O        2 ['4O8', '4o8', 'NN', 'O', 'O']\n",
      "1346         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      " 280         O         O       -3 [',', ',', ',', 'O', 'O']\n",
      " 281         O         O       -2 ['USA', 'USA', 'NNP', 'LOCATION', 'O']\n",
      " 282         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      " 283         O B-Element    <ERR> ['13Oregon', '13Oregon', 'NNP', 'O', 'O']\n",
      " 284         O         O        1 ['State', 'State', 'NNP', 'ORGANIZATION', 'O']\n",
      " 285         O         O        2 ['University', 'University', 'NNP', 'ORGANIZATION', 'O']\n",
      " 286         O         O        3 [',', ',', ',', 'O', 'O']\n",
      "\n",
      "  83         O         O       -3 ['3CalTech', '3CalTech', 'NNP', 'O', 'O']\n",
      "  84         O         O       -2 [',', ',', ',', 'O', 'O']\n",
      "  85         O         O       -1 ['4Washington', '4Washington', 'NNP', 'O', 'O']\n",
      "  86         O B-Element    <ERR> ['U.', 'U.', 'NNP', 'O', 'O']\n",
      "  87         O         O        1 [',', ',', ',', 'O', 'O']\n",
      "  88         O         O        2 ['5MSSS', '5msss', 'NN', 'O', 'O']\n",
      "  89         O         O        3 [',', ',', ',', 'O', 'O']\n",
      "\n",
      " 205         O         O       -3 ['to', 'to', 'TO', 'O', 'O']\n",
      " 206         O         O       -2 ['estimate', 'estimate', 'VB', 'O', 'O']\n",
      " 207         O         O       -1 ['the', 'the', 'DT', 'O', 'O']\n",
      " 208         O B-Element    <ERR> ['halogen', 'halogen', 'NN', 'O', 'O']\n",
      " 209         O         O        1 ['budget', 'budget', 'NN', 'O', 'O']\n",
      " 210         O         O        2 ['of', 'of', 'IN', 'O', 'O']\n",
      " 211         O         O        3 ['Mars', 'Mars', 'NNP', 'O', 'O']\n",
      "\n",
      " 778         O         O       -3 ['1', '1', 'CD', 'NUMBER', 'O']\n",
      " 779         O         O       -2 ['Ca', 'ca', 'NN', 'O', 'O']\n",
      " 780         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 781         O B-Element    <ERR> ['F', 'f', 'NN', 'O', 'O']\n",
      " 782         O         O        1 [',', ',', ',', 'O', 'O']\n",
      " 783         O B-Element        2 ['Cl', 'cl', 'NN', 'O', 'O']\n",
      " 784         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      " 780         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 781         O B-Element       -2 ['F', 'f', 'NN', 'O', 'O']\n",
      " 782         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      " 783         O B-Element    <ERR> ['Cl', 'cl', 'NN', 'O', 'O']\n",
      " 784         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      " 785         O         O        2 ['2', '2', 'CD', 'NUMBER', 'O']\n",
      " 786         O         O        3 ['Ca10', 'ca10', 'NN', 'O', 'O']\n",
      "\n",
      " 789         O         O       -3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      " 790         O         O       -2 ['6', '6', 'CD', 'NUMBER', 'O']\n",
      " 791         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 792         O B-Element    <ERR> ['F', 'f', 'NN', 'O', 'O']\n",
      " 793         O         O        1 [',', ',', ',', 'O', 'O']\n",
      " 794         O B-Element        2 ['Cl', 'cl', 'NN', 'O', 'O']\n",
      " 795         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      "\n",
      " 791         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O', 'O']\n",
      " 792         O B-Element       -2 ['F', 'f', 'NN', 'O', 'O']\n",
      " 793         O         O       -1 [',', ',', ',', 'O', 'O']\n",
      " 794         O B-Element    <ERR> ['Cl', 'cl', 'NN', 'O', 'O']\n",
      " 795         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      " 796         O         O        2 ['2', '2', 'CD', 'NUMBER', 'O']\n",
      " 797         O         O        3 ['These', 'these', 'DT', 'O', 'O']\n",
      "\n",
      " 866         O         O       -3 ['of', 'of', 'IN', 'O', 'O']\n",
      " 867 B-Element B-Element       -2 ['F', 'f', 'NN', 'O', 'B-Element']\n",
      " 868         O         O       -1 ['and', 'and', 'CC', 'O', 'O']\n",
      " 869         O B-Element    <ERR> ['Cl', 'cl', 'NN', 'O', 'O']\n",
      " 870         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O', 'O']\n",
      " 871         O         O        2 ['.', '.', '.', 'O', 'O']\n",
      " 872         O         O        3 ['|', '|', '|', 'O', 'O']\n",
      "\n",
      "1301         O         O       -3 ['Anderson', 'Anderson', 'NNP', 'PERSON', 'O']\n",
      "1302         O         O       -2 [',', ',', ',', 'O', 'O']\n",
      "1303         O         O       -1 ['R.', 'R.', 'NNP', 'O', 'O']\n",
      "1304         O B-Element    <ERR> ['B.', 'B.', 'NNP', 'O', 'O']\n",
      "1305         O         O        1 [',', ',', ',', 'O', 'O']\n",
      "1306         O         O        2 ['et', 'et', 'FW', 'O', 'O']\n",
      "1307         O         O        3 ['al.', 'al.', 'FW', 'O', 'O']\n",
      "\n",
      "1330         O         O       -3 ['Spectrochimica', 'Spectrochimica', 'NNP', 'O', 'O']\n",
      "1331         O         O       -2 ['Acta', 'Acta', 'NNP', 'O', 'O']\n",
      "1332         O         O       -1 ['Part', 'Part', 'NNP', 'O', 'O']\n",
      "1333         O B-Element    <ERR> ['B', 'B', 'NNP', 'O', 'O']\n",
      "1334         O         O        1 [':', ':', ':', 'O', 'O']\n",
      "1335         O         O        2 ['Atomic', 'atomic', 'JJ', 'O', 'O']\n",
      "1336         O         O        3 ['Spectroscopy', 'spectroscopy', 'NN', 'O', 'O']\n",
      "\n",
      "1384         O         O       -3 ['-RSB-', '-rsb-', '-RRB-', 'O', 'O']\n",
      "1385         O         O       -2 ['Schr', 'Schr', 'NNP', 'O', 'O']\n",
      "1386         O         O       -1 ['der', 'der', 'NNP', 'O', 'O']\n",
      "1387         O B-Element    <ERR> ['S.', 'S.', 'NNP', 'O', 'O']\n",
      "1388         O         O        1 [',', ',', ',', 'O', 'O']\n",
      "1389         O         O        2 ['et', 'et', 'FW', 'O', 'O']\n",
      "1390         O         O        3 ['al.', 'al.', 'FW', 'O', 'O']\n",
      "\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model_file)\n",
    "\n",
    "with open(dev_corpus_file, 'rb') as f:\n",
    "    dev_corpus = pickle.load(f)\n",
    "\n",
    "ctx = (-3, 4)\n",
    "c = 0\n",
    "print(\"idx, Truth, Predicted, Word, Comment \")\n",
    "for doc in dev_corpus:\n",
    "    seq = merge_sequences(doc)\n",
    "    y = seq2labels(seq)\n",
    "    y_ = tagger.tag(seq2features(seq))\n",
    "    \n",
    "    for idx in range(len(seq)):\n",
    "        a, p, tok = y[idx], y_[idx], seq[idx]\n",
    "        if a == 'O' and p == 'B-Element':\n",
    "            for pos in filter(lambda p: 0 <= p < len(seq), range(idx+ctx[0], idx+ctx[1])):\n",
    "                if idx == pos:\n",
    "                    label = \"<CORR>\" if a == p else \"<ERR>\"\n",
    "                else:\n",
    "                    label = \"%d\" % (pos - idx)\n",
    "                print(\"%4d %9s %9s %8s %s\" % (pos, y[pos], y_[pos], label, str(seq[pos])))\n",
    "            print(\"\")\n",
    "            if a != p:\n",
    "                c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "### Interpretation of matrix\n",
    "Row sum is total true labels\n",
    "Column sum is predictions total labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set\n",
      "***,B-Mineral,I-Mineral,B-Target,I-Target,B-Element,I-Element,O,total\n",
      "B-Mineral,0,312,0,0,0,0,0,312\n",
      "I-Mineral,0,3,0,0,0,0,0,3\n",
      "B-Target,0,194,0,0,0,0,0,194\n",
      "I-Target,0,20,0,0,0,0,0,20\n",
      "B-Element,0,458,0,0,0,0,0,458\n",
      "I-Element,0,0,0,0,0,0,0,0\n",
      "Precision,0,0.0000,0,0,0,0,0,0\n",
      "Recall,0.0000,1.0000,0.0000,0.0000,0.0000,0,0,0\n",
      "\n",
      "O,0,59643,0,0,0,0,0,59643\n",
      "total,0,60630,0,0,0,0,0,60630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "test_corpus_file = 'mte-corpus-test.pickle'\n",
    "printtable(*evaluate(tagger, test_corpus_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  B-Element       0.85      0.80      0.82       375\n",
      "  B-Mineral       0.80      0.46      0.59       240\n",
      "   B-Target       0.85      0.16      0.26       147\n",
      "   I-Target       0.83      0.36      0.50        14\n",
      "\n",
      "avg / total       0.99      0.99      0.99     34970\n",
      "\n",
      "Testing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  B-Element       0.87      0.86      0.86       458\n",
      "  B-Mineral       0.76      0.54      0.64       312\n",
      "  I-Mineral       0.00      0.00      0.00         3\n",
      "   B-Target       0.93      0.21      0.34       194\n",
      "   I-Target       0.78      0.35      0.48        20\n",
      "\n",
      "avg / total       0.84      0.62      0.68       987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    #tagset.append('O')\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "def evaluate(tagger, corpus_file):    \n",
    "    corpus = pickle.load(open(corpus_file, 'rb'))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for doc in corpus:\n",
    "        seq = merge_sequences(doc)\n",
    "        y_true.append(seq2labels(seq))\n",
    "        y_pred.append(tagger.tag(seq2features(seq)))\n",
    "    return bio_classification_report(y_true, y_pred)\n",
    "\n",
    "\n",
    "dev_corpus_file = 'mte-corpus-dev.pickle'\n",
    "test_corpus_file = 'mte-corpus-test.pickle'\n",
    "print(\"Development\")\n",
    "print(evaluate(tagger, dev_corpus_file))\n",
    "\n",
    "print(\"Testing\")\n",
    "print(evaluate(tagger, test_corpus_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning: State Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-Target -> B-Target 2.386108\n",
      "B-Target -> I-Target 2.208480\n",
      "I-Mineral -> I-Mineral 2.114082\n",
      "I-Target -> B-Target 2.111899\n",
      "B-Mineral -> I-Mineral 1.460643\n",
      "O      -> O       1.213288\n",
      "B-Element -> I-Element 0.872641\n",
      "I-Target -> I-Target 0.816825\n",
      "B-Mineral -> B-Mineral 0.156233\n",
      "O      -> B-Mineral 0.151186\n",
      "B-Mineral -> O       0.115508\n",
      "I-Target -> O       0.043102\n",
      "O      -> B-Target 0.039404\n",
      "I-Mineral -> O       0.035210\n",
      "B-Element -> O       -0.018350\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-Element -> I-Mineral -0.294718\n",
      "B-Target -> B-Mineral -0.296192\n",
      "I-Element -> O       -0.393103\n",
      "I-Target -> B-Element -0.516234\n",
      "B-Element -> B-Element -0.554523\n",
      "B-Mineral -> B-Element -0.687627\n",
      "B-Target -> O       -0.748083\n",
      "B-Mineral -> B-Target -0.835439\n",
      "B-Mineral -> I-Target -0.917494\n",
      "B-Element -> B-Mineral -1.130964\n",
      "B-Target -> B-Element -1.475913\n",
      "O      -> I-Element -2.597084\n",
      "B-Element -> I-Target -4.038288\n",
      "O      -> I-Mineral -7.106403\n",
      "O      -> I-Target -8.379464\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning: State Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "8.058676 O      0word[-2:]=be\n",
      "6.673286 B-Mineral 0word.shape=ccvcvcccvcvcv\n",
      "6.495373 O      0word.genpos=DT\n",
      "6.414756 B-Element 0word[-2:]=Ho\n",
      "6.412245 B-Element 0word[-2:]=Sn\n",
      "6.403895 O      0word[-2:]=We\n",
      "5.984024 O      0word[-1:]=A\n",
      "5.793493 B-Target 0word[-2:]=CB\n",
      "5.733161 B-Element 0word[-2:]=Dy\n",
      "5.418787 B-Target 0word[-2:]=JK\n",
      "5.315773 B-Element 0word[-2:]=Ag\n",
      "5.286066 O      0word.shape=vcvvcvccvvc\n",
      "5.140279 O      0word[-1:]=Q\n",
      "5.037365 O      0word[-2:]=Ma\n",
      "5.005682 B-Element 0word[-2:]=Eu\n",
      "4.958816 B-Mineral 0word.shape=vcvcvcv\n",
      "4.941674 O      0word.shape=ccvcvcvcvccvcv\n",
      "4.894968 O      0word[-1:]=T\n",
      "4.866134 O      0word[-1:]=G\n",
      "4.829303 O      -1word.shape=dddd.ccc\n",
      "\n",
      "Top negative:\n",
      "-2.700686 O      0word.shape=v\n",
      "-2.731780 O      0word[-3:]=aat\n",
      "-2.736311 O      0word.shape=cvccvcvc\n",
      "-2.753581 B-Element 0word[-2:]=ed\n",
      "-2.758393 O      0word[-3:]=fur\n",
      "-2.770790 B-Element 0word.ner=LOCATION\n",
      "-2.814486 O      0word[-3:]=gen\n",
      "-2.876500 I-Target 0word.islower=True\n",
      "-3.049026 O      0word.shape=cccccvcvcvcvcv\n",
      "-3.206710 O      0word.shape=cvccccvcc\n",
      "-3.278055 O      0word[-2:]=Mo\n",
      "-3.305678 O      0word[-2:]=La\n",
      "-3.319855 O      0word[-3:]=bon\n",
      "-3.344219 B-Target -1word.ner=PERSON\n",
      "-3.418571 O      0word[-2:]=Lu\n",
      "-3.455216 O      0word.shape=ccvcvvccvcv\n",
      "-3.716405 O      0word[-3:]=kel\n",
      "-3.971070 O      0word.shape=cccccvcvcvcvcvc\n",
      "-5.492894 O      0word[-3:]=for\n",
      "-5.822459 O      0word.shape=cccvcvcv\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-213-64e54bd3b239>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-213-64e54bd3b239>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    a, b, c =  *arr\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "arr = ['a', 'b', 'c']\n",
    "a, b, c =  *arr\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cvcvc N N'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s = \"hellow 124.45 -65.7623\"\n",
    "get_wordshape_sound_case(\"hellow 124.45 -65.7623\")\n",
    "#get_wordshape_sound(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abcd\"[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
