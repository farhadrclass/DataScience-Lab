{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following source code downloads and loads the images and the corresponding labels into memory\n",
    "import mxnet as mx\n",
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following source code initializes the data iterators for the MNIST dataset. \n",
    "# Note that we initialize two iterators: one for train data and one for test data\n",
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The first approach makes use of a Multilayer Perceptron to solve this problem\n",
    "data = mx.sym.var('data')\n",
    "# Flatten the data from 4-D shape into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.flatten(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code declares two fully connected layers with 128 and 64 neurons each\n",
    "# The first fully-connected layer and the corresponding activation function\n",
    "fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the corresponding activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, act_type=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following source code declares the final fully connected layer of size 10\n",
    "# MNIST has 10 classes\n",
    "fc3  = mx.sym.FullyConnected(data=act2, num_hidden=10)\n",
    "# Softmax with cross entropy loss\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 27720.29 samples/sec\taccuracy=0.111980\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 26618.65 samples/sec\taccuracy=0.111600\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 26824.49 samples/sec\taccuracy=0.113500\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 27890.74 samples/sec\taccuracy=0.115100\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 27234.01 samples/sec\taccuracy=0.169900\n",
      "INFO:root:Epoch[0] Train-accuracy=0.255354\n",
      "INFO:root:Epoch[0] Time cost=2.274\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.332700\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 27562.17 samples/sec\taccuracy=0.501386\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 27188.94 samples/sec\taccuracy=0.699900\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 27874.95 samples/sec\taccuracy=0.792200\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 27452.63 samples/sec\taccuracy=0.823200\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 27242.34 samples/sec\taccuracy=0.841400\n",
      "INFO:root:Epoch[1] Train-accuracy=0.868990\n",
      "INFO:root:Epoch[1] Time cost=2.195\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.871300\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 27108.14 samples/sec\taccuracy=0.870396\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 27628.86 samples/sec\taccuracy=0.896100\n",
      "INFO:root:Epoch[2] Batch [300]\tSpeed: 27032.57 samples/sec\taccuracy=0.898400\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 25190.21 samples/sec\taccuracy=0.902600\n",
      "INFO:root:Epoch[2] Batch [500]\tSpeed: 27125.99 samples/sec\taccuracy=0.907800\n",
      "INFO:root:Epoch[2] Train-accuracy=0.917071\n",
      "INFO:root:Epoch[2] Time cost=2.243\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.917400\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 27678.07 samples/sec\taccuracy=0.920792\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 27432.83 samples/sec\taccuracy=0.932100\n",
      "INFO:root:Epoch[3] Batch [300]\tSpeed: 27099.96 samples/sec\taccuracy=0.934500\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 27754.18 samples/sec\taccuracy=0.934600\n",
      "INFO:root:Epoch[3] Batch [500]\tSpeed: 26398.10 samples/sec\taccuracy=0.937800\n",
      "INFO:root:Epoch[3] Train-accuracy=0.942222\n",
      "INFO:root:Epoch[3] Time cost=2.204\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.944400\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 27688.15 samples/sec\taccuracy=0.944059\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 26713.24 samples/sec\taccuracy=0.950200\n",
      "INFO:root:Epoch[4] Batch [300]\tSpeed: 27566.50 samples/sec\taccuracy=0.953400\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 26397.73 samples/sec\taccuracy=0.950800\n",
      "INFO:root:Epoch[4] Batch [500]\tSpeed: 28067.15 samples/sec\taccuracy=0.954000\n",
      "INFO:root:Epoch[4] Train-accuracy=0.955152\n",
      "INFO:root:Epoch[4] Time cost=2.199\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.955300\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 27498.57 samples/sec\taccuracy=0.955545\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 28035.84 samples/sec\taccuracy=0.961500\n",
      "INFO:root:Epoch[5] Batch [300]\tSpeed: 27687.20 samples/sec\taccuracy=0.963300\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 28032.39 samples/sec\taccuracy=0.962500\n",
      "INFO:root:Epoch[5] Batch [500]\tSpeed: 27600.01 samples/sec\taccuracy=0.960700\n",
      "INFO:root:Epoch[5] Train-accuracy=0.963535\n",
      "INFO:root:Epoch[5] Time cost=2.179\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.962800\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 28020.68 samples/sec\taccuracy=0.963861\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 25918.89 samples/sec\taccuracy=0.968100\n",
      "INFO:root:Epoch[6] Batch [300]\tSpeed: 27786.38 samples/sec\taccuracy=0.970500\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 26349.57 samples/sec\taccuracy=0.966900\n",
      "INFO:root:Epoch[6] Batch [500]\tSpeed: 26360.55 samples/sec\taccuracy=0.966300\n",
      "INFO:root:Epoch[6] Train-accuracy=0.969293\n",
      "INFO:root:Epoch[6] Time cost=2.229\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.965600\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 27264.93 samples/sec\taccuracy=0.970297\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 28227.19 samples/sec\taccuracy=0.973600\n",
      "INFO:root:Epoch[7] Batch [300]\tSpeed: 28557.02 samples/sec\taccuracy=0.973300\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 27955.06 samples/sec\taccuracy=0.971100\n",
      "INFO:root:Epoch[7] Batch [500]\tSpeed: 28567.74 samples/sec\taccuracy=0.972100\n",
      "INFO:root:Epoch[7] Train-accuracy=0.974747\n",
      "INFO:root:Epoch[7] Time cost=2.140\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.966700\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 26666.18 samples/sec\taccuracy=0.973564\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 27726.81 samples/sec\taccuracy=0.976900\n",
      "INFO:root:Epoch[8] Batch [300]\tSpeed: 27666.11 samples/sec\taccuracy=0.977400\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 28359.38 samples/sec\taccuracy=0.974500\n",
      "INFO:root:Epoch[8] Batch [500]\tSpeed: 28271.14 samples/sec\taccuracy=0.974800\n",
      "INFO:root:Epoch[8] Train-accuracy=0.977374\n",
      "INFO:root:Epoch[8] Time cost=2.176\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.967300\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 25299.98 samples/sec\taccuracy=0.977030\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 27723.42 samples/sec\taccuracy=0.979800\n",
      "INFO:root:Epoch[9] Batch [300]\tSpeed: 28389.59 samples/sec\taccuracy=0.980400\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 27730.81 samples/sec\taccuracy=0.977000\n",
      "INFO:root:Epoch[9] Batch [500]\tSpeed: 26391.35 samples/sec\taccuracy=0.977900\n",
      "INFO:root:Epoch[9] Train-accuracy=0.978788\n",
      "INFO:root:Epoch[9] Time cost=2.207\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.969900\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n",
    "# create a trainable module on CPU\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())\n",
    "mlp_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='sgd',  # use SGD to train\n",
    "              optimizer_params={'learning_rate':0.1},  # use fixed learning rate\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "              batch_end_callback = mx.callback.Speedometer(batch_size, 100), # output progress for each 100 data batches\n",
    "              num_epoch=10)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can evaluate the trained model by running predictions on test data\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\n",
    "prob = mlp_model.predict(test_iter)\n",
    "assert prob.shape == (10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "data = mx.sym.var('data')\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=pool2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "# second fullc\n",
    "fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n",
    "# softmax loss\n",
    "lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 836.49 samples/sec\taccuracy=0.112277\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 871.48 samples/sec\taccuracy=0.111600\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 886.76 samples/sec\taccuracy=0.113500\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 882.46 samples/sec\taccuracy=0.115100\n",
      "INFO:root:Epoch[0] Batch [500]\tSpeed: 891.08 samples/sec\taccuracy=0.107300\n",
      "INFO:root:Epoch[0] Train-accuracy=0.111616\n",
      "INFO:root:Epoch[0] Time cost=68.797\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.113500\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 881.15 samples/sec\taccuracy=0.115050\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 878.31 samples/sec\taccuracy=0.409000\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 855.11 samples/sec\taccuracy=0.837400\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 866.94 samples/sec\taccuracy=0.886200\n",
      "INFO:root:Epoch[1] Batch [500]\tSpeed: 854.77 samples/sec\taccuracy=0.914500\n",
      "INFO:root:Epoch[1] Train-accuracy=0.931111\n",
      "INFO:root:Epoch[1] Time cost=69.741\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.937500\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 839.20 samples/sec\taccuracy=0.942277\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 859.48 samples/sec\taccuracy=0.953500\n",
      "INFO:root:Epoch[2] Batch [300]\tSpeed: 878.24 samples/sec\taccuracy=0.958600\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 866.66 samples/sec\taccuracy=0.961200\n",
      "INFO:root:Epoch[2] Batch [500]\tSpeed: 817.56 samples/sec\taccuracy=0.967100\n",
      "INFO:root:Epoch[2] Train-accuracy=0.966667\n",
      "INFO:root:Epoch[2] Time cost=70.497\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.969300\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 856.15 samples/sec\taccuracy=0.969406\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 857.90 samples/sec\taccuracy=0.973900\n",
      "INFO:root:Epoch[3] Batch [300]\tSpeed: 811.73 samples/sec\taccuracy=0.976100\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 818.45 samples/sec\taccuracy=0.975000\n",
      "INFO:root:Epoch[3] Batch [500]\tSpeed: 847.17 samples/sec\taccuracy=0.977800\n",
      "INFO:root:Epoch[3] Train-accuracy=0.976970\n",
      "INFO:root:Epoch[3] Time cost=71.511\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.978800\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 851.25 samples/sec\taccuracy=0.977426\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 854.39 samples/sec\taccuracy=0.980900\n",
      "INFO:root:Epoch[4] Batch [300]\tSpeed: 810.67 samples/sec\taccuracy=0.983300\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 848.12 samples/sec\taccuracy=0.981400\n",
      "INFO:root:Epoch[4] Batch [500]\tSpeed: 861.80 samples/sec\taccuracy=0.981800\n",
      "INFO:root:Epoch[4] Train-accuracy=0.982727\n",
      "INFO:root:Epoch[4] Time cost=70.926\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.983300\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 837.96 samples/sec\taccuracy=0.981980\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 809.15 samples/sec\taccuracy=0.984300\n",
      "INFO:root:Epoch[5] Batch [300]\tSpeed: 824.55 samples/sec\taccuracy=0.986100\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 831.89 samples/sec\taccuracy=0.985300\n",
      "INFO:root:Epoch[5] Batch [500]\tSpeed: 850.10 samples/sec\taccuracy=0.984000\n",
      "INFO:root:Epoch[5] Train-accuracy=0.986465\n",
      "INFO:root:Epoch[5] Time cost=71.775\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.985800\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 818.61 samples/sec\taccuracy=0.984851\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 818.92 samples/sec\taccuracy=0.987300\n",
      "INFO:root:Epoch[6] Batch [300]\tSpeed: 849.76 samples/sec\taccuracy=0.988600\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 839.89 samples/sec\taccuracy=0.987600\n",
      "INFO:root:Epoch[6] Batch [500]\tSpeed: 838.64 samples/sec\taccuracy=0.986400\n",
      "INFO:root:Epoch[6] Train-accuracy=0.988990\n",
      "INFO:root:Epoch[6] Time cost=71.941\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.987200\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 821.96 samples/sec\taccuracy=0.986535\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 847.79 samples/sec\taccuracy=0.989300\n",
      "INFO:root:Epoch[7] Batch [300]\tSpeed: 835.53 samples/sec\taccuracy=0.990200\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 872.89 samples/sec\taccuracy=0.990100\n",
      "INFO:root:Epoch[7] Batch [500]\tSpeed: 857.24 samples/sec\taccuracy=0.989000\n",
      "INFO:root:Epoch[7] Train-accuracy=0.990606\n",
      "INFO:root:Epoch[7] Time cost=71.214\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.987400\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 842.14 samples/sec\taccuracy=0.987228\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 836.98 samples/sec\taccuracy=0.991100\n",
      "INFO:root:Epoch[8] Batch [300]\tSpeed: 843.14 samples/sec\taccuracy=0.991200\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 847.13 samples/sec\taccuracy=0.992100\n",
      "INFO:root:Epoch[8] Batch [500]\tSpeed: 804.45 samples/sec\taccuracy=0.990800\n",
      "INFO:root:Epoch[8] Train-accuracy=0.992121\n",
      "INFO:root:Epoch[8] Time cost=71.574\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.987600\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 847.33 samples/sec\taccuracy=0.988515\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 832.08 samples/sec\taccuracy=0.992400\n",
      "INFO:root:Epoch[9] Batch [300]\tSpeed: 847.39 samples/sec\taccuracy=0.992700\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 822.23 samples/sec\taccuracy=0.992800\n",
      "INFO:root:Epoch[9] Batch [500]\tSpeed: 834.39 samples/sec\taccuracy=0.992100\n",
      "INFO:root:Epoch[9] Train-accuracy=0.992929\n",
      "INFO:root:Epoch[9] Time cost=71.696\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.987600\n"
     ]
    }
   ],
   "source": [
    "# create a trainable module on GPU 0\n",
    "lenet_model = mx.mod.Module(symbol=lenet, context=mx.cpu())\n",
    "# train with the same\n",
    "lenet_model.fit(train_iter,\n",
    "                eval_data=val_iter,\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.1},\n",
    "                eval_metric='acc',\n",
    "                batch_end_callback = mx.callback.Speedometer(batch_size, 100),\n",
    "                num_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalMetric: {'accuracy': 0.98760000000000003}\n"
     ]
    }
   ],
   "source": [
    "#  use the trained LeNet model to generate predictions for the test data\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\n",
    "prob = lenet_model.predict(test_iter)\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n",
    "# predict accuracy for lenet\n",
    "acc = mx.metric.Accuracy()\n",
    "lenet_model.score(test_iter, acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
